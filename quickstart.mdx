---
title: "Quickstart"
description: "Build with LLM7.io in minutes: chat, images, and more."
---

## Get started in three steps

Spin up the OpenAI SDK against the LLM7.io endpoint and make your first requests.

### Step 1: Set up

<AccordionGroup>
  <Accordion icon="rectangle-terminal" title="Install the SDK">

```bash
pip install openai
````

  </Accordion>

  <Accordion icon="key" title="Configure the client" defaultOpen>
    You can use LLM7.io without a key for low-volume use. For higher limits, get a free token at [token.llm7.io](https://token.llm7.io/).

```python
import openai

client = openai.OpenAI(
    base_url="https://api.llm7.io/v1",
    api_key="unused",  # or your token from https://token.llm7.io/
)
```


  </Accordion>
</AccordionGroup>

### Step 2: Text generation

<AccordionGroup>
  <Accordion icon="square-code" title="Chat completions (Python)" defaultOpen>

```python
import openai

client = openai.OpenAI(
    base_url="https://api.llm7.io/v1",
    api_key="unused",  # replace if you have a token
)

resp = client.chat.completions.create(
    model="default",
    messages=[
        {"role": "user", "content": "Tell me a short story about a brave squirrel."}
    ],
)

print(resp.choices[0].message.content)
```

The output will be a short story generated by the model, for example:

```
Once upon a time, in a lush green forest, there lived a brave squirrel named Sammy. Sammy was known for his adventurous spirit and his willingness to help others. One day, a fierce storm hit the forest, causing a massive tree to fall and block the entrance to the squirrel village. Without hesitation, Sammy gathered his friends and devised a plan to clear the path. With teamwork and determination, they managed to move the fallen tree and restore access to their home. The villagers celebrated Sammy's bravery, and he became a legend in the forest for his courageous act.
```

</Accordion>
</AccordionGroup>

### Step 3: Image generation

<AccordionGroup>
  <Accordion icon="image" title="Images API (Python)">

```python
from openai import OpenAI

client = OpenAI(base_url="https://api.llm7.io/v1", api_key="none")

prompt = (
    "A futuristic cityscape at sunset, flying cars, neon reflections, "
    "cinematic cyberpunk, highly detailed"
)

res = client.images.generate(
    model="flux",
    prompt=prompt,
    size="1024x1024",
    extra_body={"seed": 42},
)

print(f"See: {res.data[0].url}")
```

The output will be a URL to the generated image, for example:

```
See: https://wsrv.nl/?url=https://api.llm7.io/i/Xr45.jpeg&maxage=31d
```

Which displays an image like this:

![A futuristic cityscape at sunset, flying cars, neon reflections, cinematic cyberpunk, highly detailed](https://wsrv.nl/?url=https://api.llm7.io/i/Xr45.jpeg&maxage=31d)

</Accordion>
</AccordionGroup>

## Next steps

<CardGroup cols={2}>

<Card title="Function calling" icon="brackets-curly" href="/guides/function-calling">
  Bind tool calls to your own functions reliably.
</Card>

<Card title="JSON mode" icon="code" href="/guides/json-mode">
  Get guaranteed JSON outputs for structured use-cases.
</Card>

<Card title="Streaming" icon="bolt" href="/guides/streaming">
  Stream tokens for lower latency UIs.
</Card>

<Card title="Image generation" icon="image" href="/vision/image-generation">
  Advanced prompts, seeds, and sizing options.
</Card>

<Card title="Audio transcription" icon="waveform" href="/audio/transcription">
  Turn speech into text with a single call.
</Card>

<Card title="API reference" icon="book" href="/api-reference/introduction">
  Endpoints, models, and schemas in one place.
</Card>

</CardGroup>

<Note>
  **Need help?** Check the API reference above or join the community.
</Note>